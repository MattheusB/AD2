---
title: "Predição de Votação de Deputados"
author: "Mattheus Brito Rodrigues"
date: "30/10/2018"
output: html_document
---
# Introdução
Esta análise será feita uitlizando dados sobre a votação de candidatos à Câmara Federal de Deputados. Onde será feita algumas predições dessas votações. Logo abaixo será respondido 5 perguntas tomando como base os dados fornecidos.

Antes de tudo será importado as nossas bibliotecas que serão utilizadas para a plotagem das análises para responder as questões.

```{r setup, include=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(caret)
library(dplyr)
library(lars)
library(ggplot2)
```

Logo após, será importado a nossa base de dados, sendo elas: train.csv (conjunto de treino que contém dados das eleições dos anos de 2006 e 2010), test.csv (conjunto de teste que contém dados das eleições de 2014). Assim como remover informações que tem pouca relevância, como nome e cargo que iriam demandar um custo elevado de tempo e atrapalhar no processo de tunagem e por fim substituir dados com NA para 0, pois utilizar dados com NA não é de bom uso.

```{r}
treino <- read.csv("~/Downloads/AD2/Lab03/train.csv", encoding = "latin1")
teste <- read.csv("~/Downloads/AD2/Lab03/test.csv", encoding = "latin1")

treino <- treino %>%
  select(-c(cargo, nome))

teste <- teste %>%
  select(-c(cargo, nome))

treino[is.na(treino)] <- 0
teste[is.na(teste)] <- 0


```

Antes de partir para as perguntas, é necessário entender o que cada coluna presente nos nossos dados significa:

* "sequencial_candidato" :(character) id do candidato
* "nome": (character)
* "uf": (character)
* "partido": (character)
* "quantidade_doacoes": (integer)
* "quantidade_doadores": (integer) número de doadores diferentes
* "total_receita": (double) soma em R$ das doações
* "media_receita": (double) média das doações
* "recursos_de_outros_candidatos/comites": (double) quantia em R$ das doações provenientes de outros candidatos ou comite partidário
* "recursos_de_pessoas_fisicas": (double) quantia em R$ das doações provenientes de outros CPFs
* "recursos_de_pessoas_juridicas": (double) quantia em R$ das doações provenientes de outros CNPJ
* "recursos_proprios": (double) quantia em R$ das doações provenientes do próprio candidato
* "recursos_de_partido_politico": (double) quantia em R$ das doações provenientes do partido político do candidato
* "votos": (integer) variável alvo. Se refere ao número de votos na campanha de 2006 e 2010
* "quantidade_despesas": (integer)
* "quantidade_fornecedores": (integer) número de fornecedores/despesas diferentes
* "total_despesa": (double) soma em R$ das despesas de campanha
* "media_despesa": (double) média das despesas de campanha
* "cargo": (character)
* "Sexo":  (character)
* "grau": (character) grau de instrução do candidato
* "estado_civil": (character)
* "ocupacao": (character) ocupação do candidato

Após entender as variáveis disponíveis, poderemos partir para a resolução das perguntas.

# Perguntas

#### 1 - Usando todas as variáveis disponíveis, tune (usando validação cruzada): (i) um modelo de regressão Ridge, (ii) um modelo de regressão Lasso e (iii) um modelo KNN. Para os modelos de regressão linear, o parâmetro a ser tunado é o lambda (penalização dos coeficientes) e o KNN o número de vizinhos.

Para realizar a tunagem das nossas variáveis vamos utilizar validação cruzada. Ou seja, teremos que fazer ums buca para encontrar os melhores valores para que o teste seja melhor. Sendo assim, segue o passo de utilizar validação cruzada:

```{r}
controleFit <- trainControl(method = "cv",
                            number = 20,
                            repeats = 20)

valoresPreProcessados <- c("center", "scale", "nzv")
```

* Modelo de regressão Ridge

Ridge regression é um método de regularização que tem como principal objetivo suavizar os atributos que aumentem o ruído no modelo, evitando o overffiting.

```{r eval = FALSE}
modeloRidge <- train(votos ~ .,
                      data = treino,
                      trControl = controleFit,
                      method = "ridge",
                      preProcess = valoresPreProcessados,
                      tuneLength = 15)
modeloRidge
```

Com o resultado do modelo, podemos observar o lambda com o valor de 0,004124626, ou seja, bem próximo a 0 que significa que o Bias é baixo e a variância alta.

* Modelo de regressão Lasso

O lasso, é um método de análise de regressão que executa a seleção e regularização de variáveis para aumentar a precisão da predição, podendo selecionar as variáveis para 0 se necessário.

```{r eval=FALSE}
modeloLasso <- train(votos ~ .,
                     data = treino,
                     trControl = controleFit,
                     method = "lasso",
                     preProcess = valoresPreProcessados,
                     tuneLength = 14)
modeloLasso
```

Após o resultado acima, podemos ver que a fração tem o valor de 0,1 onde o Rsquared é melhor, assumindo o valor de 0,4795668.

* Modelo KNN

O modelo KNN vai fazer uma busca dos elementos que estão mais próximos para dar um match em seus resultados, ou seja, se um valor x está mais perto de y do que de z, ela terá o valor y por estar mais próxima.

```{r eval=FALSE}
modeloKNN <- train(votos ~ .,
                   data = treino,
                   trControl = controleFit,
                   method = "knn",
                   preProcess = valoresPreProcessados,
                   tuneLength = 15)

modeloKNN
```

O resultado mostrou k = 13 onde o Rsquared assume o valor de 0,5072944.

#### 2 - Compare os três modelos em termos do erro RMSE de validação cruzada.

Para fazer a comparação dos três modelos em termos do erro RMSE da validação realizada na questão passada podemos plotar três gráficos utilizando x = Lambda e y = RMSE.

```{r eval=FALSE}
plot(modeloRidge, xlab = "Lambda", ylab = "RMSE")
plot(modeloLasso, xlab = "Lambda", ylab = "RMSE")
plot(modeloKNN, ylab = "RMSE")
```

Pelos resultados obtidos nas análises passados, obtemos os seguintes RMSE's:

* Ridge - 42346,65
* Lasso - 36808,69
* KNN - 33724,15

Podemos afirmar que apesar de todos terem um valor elevado de RMSE. Não há muita diferença entre eles, a não ser no modelo Ridge, que é um pouco mais elevados que os outros modelos.

#### 3 - Quais as variáveis mais importantes segundo o modelo de regressão Ridge e Lasso?  Variáveis foram descartadas pelo Lasso? Quais?

Para a importância das variáveis de cada modelo, vamos observar os seguintes gráficos para assim observar as variáveis que tem menos importância em cada modelo.

```{r eval=FALSE}
ggplot(varImp(modeloRidge))
```

No modelo Ridge, as varáveis "recursos_proprios", "recursos_de_outros_candidatos.comites", "media_despesa", "ano" não tem importância.

```{r eval=FALSE}
ggplot(varImp(modeloLasso))
```

No modelo Lasso, vemos as mesmas variáveis que não têm importância no Ridge.

#### 4 - Re-treine o melhor modelo usando os melhores valores de parâmetros encontrados em todos os dados, sem usar validação cruzada).

Levando em consideração o "melhor modelo", como vimos que os resultados são muito similares, vamos usar o modelo knn sem validação cruzada, tomando como base o menor valor do RMSE encontrado dentre os três modelos.

```{r}
treinoK <- treino %>% select (-ano, -recursos_de_outros_candidatos.comites, -recursos_proprios, -media_despesa)

testeK <- teste %>% select (-ano, -recursos_de_outros_candidatos.comites, -recursos_proprios, -media_despesa)
```

E retreinando ele temos:

```{r eval=FALSE}
grid <- expand.grid(k = modeloKNN$bestTune)
controle <- trainControl(method = "optimism_boot")
modeloKNNCV <- train(votos ~ ., 
               data = treinoK,
               method = "knn",
               tuneGrid = grid,
               trControl = controle,
               preProcess = valoresPreProcessados)
modeloKNNCV
```
Após o resultado, vimos que foi possível obter um Rsquared menor quando usamos o knn sem validação cruzda, tendo um Rsquared = 0,4745128 e com validação cruzada tem o Rsquared = 0,5072944.



#### 5 - Use esse último modelo treinado para prever os dados de teste disponíveis no challenge que criamos na plataforma Kaggle

Gerando o csv para submeter no desafio no Kaggle:

```{r eval = FALSE}
modeloKNNCV$xlevels[["ocupacao"]] <- union(modeloKNNCV$xlevels[["ocupacao"]], levels(testeK$ocupacao))
predicao <- predict(modeloKNNCV, testeK)
ID <- testeK %>%
  select(sequencial_candidato)
colnames(ID)[colnames(ID)=="sequencial_candidato"] <- "ID"
arquivoCSV <- ID
arquivoCSV$votos <- predicao
arquivoCSV$votos[arquivoCSV$votos < 0] <- 0
write.csv(arquivoCSV, "sample_submission.csv", row.names=FALSE)
```



