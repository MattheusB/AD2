---
title: "Predição de Votação de Deputados"
author: "Mattheus Brito Rodrigues"
date: "30/10/2018"
output: html_document
---
# Introdução
Esta análise será feita utlizando dados sobre a votação de candidatos à Câmara Federal de Deputados. Onde será feita algumas predições dessas votações. Logo abaixo será respondido 5 perguntas tomando como base os dados fornecidos.

Antes de tudo será importado as nossas bibliotecas que serão utilizadas para a plotagem das análises para responder as questões.

```{r setup, include=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(caret)
library(dplyr)
library(lars)
library(ggplot2)
```

Logo após, será importado a nossa base de dados, sendo elas: train.csv (conjunto de treino que contém dados das eleições dos anos de 2006 e 2010), test.csv (conjunto de teste que contém dados das eleições de 2014). Assim como remover informações que tem pouca relevância, como nome e cargo que iriam demandar um custo elevado de tempo e atrapalhar no processo de tunagem e por fim substituir dados com NA para 0, pois utilizar dados com NA não é de bom uso.

```{r}
treino <- read.csv("~/Downloads/AD2/Lab03/train.csv", encoding = "latin1")
teste <- read.csv("~/Downloads/AD2/Lab03/test.csv", encoding = "latin1")

treino <- treino %>%
  select(-c(cargo, nome))

teste <- teste %>%
  select(-c(cargo, nome))

treino[is.na(treino)] <- 0
teste[is.na(teste)] <- 0


```

Antes de partir para as perguntas, é necessário entender o que cada coluna presente nos nossos dados significa:

* ano: Ano da eleição;
* sequencial_candidato: O identificador do candidato. Corresponde à coluna ID do arquivo de submissão;
* nome: Nome do candidato;
* uf: Sigla do estado do candidato;
* partido: Partido do candidato;
* quantidade_doacoes: Número de doações que um candidato recebeu;
* quantidade_doadores: Numero de doadores que um candidato teve;
* total_receita: Total de receita de um candidato;
* media_receita: Média da receita de um candidato;
* recursos_de_outros_candidatos.comites: Total de receita proveniente de outros candidatos e comitês;
* recursos_de_pessoas_fisicas: Total de receita proveniente de pessoas físicas;
* recursos_de_pessoas_juridicas: Total de receita proveniente de pessoas juridicas;
* recursos_proprios:Total de receita proveniente dos próprios candidatos;
* recursos_de_partido_politico: Total de receita proveniente do partido do candidato;
* quantidade_despesas: Número de despesas que um candidato teve;
* quantidade_fornecedores: Número de fornecedores que um candidato teve;
* total_despesa: Total de depesa de um candidato;
* media_despesa: Média da despesa de um candidato;
* cargo: Cargo ao qual o candidato está concorrendo;
* sexo: Sexo do candidato;
* grau: Grau de escolaridade do candidato;
* estado_civil: Estado civil do candidato;
* ocupacao: Ocupação do candidato;
* votos: Número de votos do candidato.

Após entender as variáveis disponíveis, poderemos partir para a resolução das perguntas.

# Perguntas

#### 1 - Usando todas as variáveis disponíveis, tune (usando validação cruzada): (i) um modelo de regressão Ridge, (ii) um modelo de regressão Lasso e (iii) um modelo KNN. Para os modelos de regressão linear, o parâmetro a ser tunado é o lambda (penalização dos coeficientes) e o KNN o número de vizinhos.

Para realizar a tunagem das nossas variáveis vamos utilizar validação cruzada. Ou seja, teremos que fazer ums buca para encontrar os melhores valores para que o teste seja melhor. Sendo assim, segue o passo de utilizar validação cruzada:

```{r warning=FALSE}
controleFit <- trainControl(method = "cv",
                            number = 20,
                            repeats = 20)

valoresPreProcessados <- c("center", "scale", "nzv")
```

* Modelo de regressão Ridge

Ridge regression é um método de regularização que tem como principal objetivo suavizar os atributos que aumentem o ruído no modelo, evitando o overffiting.

```{r eval = FALSE}
modeloRidge <- train(votos ~ .,
                      data = treino,
                      trControl = controleFit,
                      method = "ridge",
                      preProcess = valoresPreProcessados,
                      tuneLength = 15)
modeloRidge
```

Com o resultado do modelo, podemos observar o lambda com o valor de 0,004124626, ou seja, bem próximo a 0 que significa que o Bias é baixo e a variância alta.

* Modelo de regressão Lasso

O lasso, é um método de análise de regressão que executa a seleção e regularização de variáveis para aumentar a precisão da predição, podendo selecionar as variáveis para 0 se necessário.

```{r eval=FALSE}
modeloLasso <- train(votos ~ .,
                     data = treino,
                     trControl = controleFit,
                     method = "lasso",
                     preProcess = valoresPreProcessados,
                     tuneLength = 14)
modeloLasso
```

Após o resultado acima, podemos ver que a fração tem o valor de 0,1 onde o Rsquared é melhor, assumindo o valor de 0,4795668.

* Modelo KNN

O modelo KNN vai fazer uma busca dos elementos que estão mais próximos para dar um match em seus resultados, ou seja, se um valor x está mais perto de y do que de z, ela terá o valor y por estar mais próxima.

```{r eval=FALSE}
modeloKNN <- train(votos ~ .,
                   data = treino,
                   trControl = controleFit,
                   method = "knn",
                   preProcess = valoresPreProcessados,
                   tuneLength = 15)

modeloKNN
```

O resultado mostrou k = 13 onde o Rsquared assume o valor de 0,5072944.

#### 2 - Compare os três modelos em termos do erro RMSE de validação cruzada.

Para fazer a comparação dos três modelos em termos do erro RMSE da validação realizada na questão passada podemos plotar três gráficos utilizando x = Lambda e y = RMSE.

```{r eval=FALSE}
plot(modeloRidge, xlab = "Lambda", ylab = "RMSE")
plot(modeloLasso, xlab = "Lambda", ylab = "RMSE")
plot(modeloKNN, ylab = "RMSE")
```

Pelos resultados obtidos nas análises passados, obtemos os seguintes RMSE's:

* Ridge - 42346,65
* Lasso - 36808,69
* KNN - 33724,15

Podemos afirmar que apesar de todos terem um valor elevado de RMSE. Não há muita diferença entre eles, a não ser no modelo Ridge, que é um pouco mais elevados que os outros modelos.

#### 3 - Quais as variáveis mais importantes segundo o modelo de regressão Ridge e Lasso?  Variáveis foram descartadas pelo Lasso? Quais?

Para a importância das variáveis de cada modelo, vamos observar os seguintes gráficos para assim observar as variáveis que tem menos importância em cada modelo.

```{r eval=FALSE}
ggplot(varImp(modeloRidge))
```

No modelo Ridge, as varáveis "recursos_proprios", "recursos_de_outros_candidatos.comites", "media_despesa", "ano" não tem importância.

```{r eval=FALSE}
ggplot(varImp(modeloLasso))
```

No modelo Lasso, vemos as mesmas variáveis que não têm importância no Ridge.

#### 4 - Re-treine o melhor modelo usando os melhores valores de parâmetros encontrados em todos os dados, sem usar validação cruzada).

Levando em consideração o "melhor modelo", como vimos que os resultados são muito similares, vamos usar o modelo knn sem validação cruzada, tomando como base o menor valor do RMSE encontrado dentre os três modelos.

```{r}
treinoK <- treino %>% select (-ano, -recursos_de_outros_candidatos.comites, -recursos_proprios, -media_despesa)

testeK <- teste %>% select (-ano, -recursos_de_outros_candidatos.comites, -recursos_proprios, -media_despesa)
```

E retreinando ele temos:

```{r eval=FALSE}
grid <- expand.grid(k = modeloKNN$bestTune)
controle <- trainControl(method = "optimism_boot")
modeloKNNCV <- train(votos ~ ., 
               data = treinoK,
               method = "knn",
               tuneGrid = grid,
               trControl = controle,
               preProcess = valoresPreProcessados)
modeloKNNCV
```
Após o resultado, vimos que foi possível obter um Rsquared menor quando usamos o knn sem validação cruzda, tendo um Rsquared = 0,4745128 e com validação cruzada tem o Rsquared = 0,5072944.



#### 5 - Use esse último modelo treinado para prever os dados de teste disponíveis no challenge que criamos na plataforma Kaggle

Gerando o csv para submeter no desafio no Kaggle:

```{r eval = FALSE}
modeloKNNCV$xlevels[["ocupacao"]] <- union(modeloKNNCV$xlevels[["ocupacao"]], levels(testeK$ocupacao))
predicao <- predict(modeloKNNCV, testeK)
ID <- testeK %>%
  select(sequencial_candidato)
colnames(ID)[colnames(ID)=="sequencial_candidato"] <- "ID"
arquivoCSV <- ID
arquivoCSV$votos <- predicao
arquivoCSV$votos[arquivoCSV$votos < 0] <- 0
write.csv(arquivoCSV, "sample_submission.csv", row.names=FALSE)
```



