---
title: "Predicao de Vota????o de Deputados"
author: "Mattheus Brito Rodrigues"
date: "30/10/2018"
output: html_document
---
# Introdu????o

```{r setup, include=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(caret)
library(dplyr)
library(lars)
library(ggplot2)
```


```{r}
dados <- read.csv("~/Downloads/AD2/Lab03/sample_submission.csv", encoding = "latin1")
dados[is.na(dados)] <- 0

tamanhoParticao <- floor(0.75 * nrow(dados))

set.seed(123)

particaoIndice <- sample(seq_len(nrow(dados)), size = tamanhoParticao, replace = TRUE)

treino <- dados[tamanhoParticao, ]
teste <- dados[-tamanhoParticao, ]

treino <- read.csv("~/Downloads/AD2/Lab03/train.csv", encoding = "latin1")
teste <- read.csv("~/Downloads/AD2/Lab03/test.csv", encoding = "latin1")

treino <- treino %>%
  select(-c(cargo, nome))

teste <- teste %>%
  select(-c(cargo, nome))

treino[is.na(treino)] <- 0
teste[is.na(teste)] <- 0


```

#Perguntas

#### 1 - Usando todas as vari??veis dispon??veis, tune (usando valida????o cruzada): (i) um modelo de regress??o Ridge, (ii) um modelo de regress??o Lasso e (iii) um modelo KNN. Para os modelos de regress??o linear, o par??metro a ser tunado ?? o lambda (penaliza????o dos coeficientes) e o KNN o n??mero de vizinhos.

```{r}
controleFit <- trainControl(method = "cv",
                            number = 20,
                            repeats = 20)

lambda.grid <- expand.grid(lambda = seq(0, 2, by=0.1))

valoresPreProcessados <- c("center", "scale", "nzv")
```



```{r eval = FALSE}
modeloRidge <- train(votos ~ .,
                      data = treino,
                      tuneGrid = lambda.grid,
                      trControl = controleFit,
                      method = "ridge",
                      preProcess = valoresPreProcessados,
                      tuneLength = 15)
modeloRidge
```

```{r}
predicaoRidge <- predict(modeloRidge)
dadosRidge <- data.frame(pred = predicaoRidge, obs = treino$votos)

ridge <- round(defaultSummary(dadosRidge), digits = 4)

ridge
```


```{r eval=FALSE}
modeloLasso <- train(votos ~ .,
                     data = treino,
                     trControl = controleFit,
                     method = "lasso",
                     preProcess = valoresPreProcessados,
                     tuneLength = 14)
modeloLasso
```

```{r}
predicaoLasso <- predict(modeloLasso)
dadosLasso <- data.frame(pred = predicaoLasso, obs = treino$votos)

lasso <- round(defaultSummary(dadosLasso), digits = 4)

lasso
```

```{r eval=FALSE}
modeloKNN <- train(votos ~ .,
                   data = treino,
                   trControl = controleFit,
                   method = "knn",
                   preProcess = valoresPreProcessados,
                   tuneLength = 15)

modeloKNN
```

```{r}
predicaoKNN <- predict(modeloKNN)
dadosKNN <- data.frame(pred = predicaoKNN, obs = treino$votos)

knn <- round(defaultSummary(dadosKNN), digits = 4)

knn
```

#### 2 - Compare os três modelos em termos do erro RMSE de validação cruzada.

```{r}
plot(modeloRidge, xlab = "Lambda", ylab = "RMSE")
plot(modeloLasso, xlab = "Lambda", ylab = "RMSE")
plot(modeloKNN, ylab = "RMSE")
```

#### 3 - Quais as variáveis mais importantes segundo o modelo de regressão Ridge e Lasso?  Variáveis foram descartadas pelo Lasso? Quais?

```{r}
ggplot(varImp(modeloRidge))
```

```{r}
ggplot(varImp(modeloLasso))
```

#### 4 - Re-treine o melhor modelo (usando os melhores valores de parâmetros encontrados em todos os dados, sem usar validação cruzada).

```{r}
treinoK <- treino %>% select (-partido, -recursos_proprios,
                           -recursos_de_outros_candidatos.comites)

testeK <- teste %>% select (-partido, -recursos_proprios,
                           -recursos_de_outros_candidatos.comites)
```

```{r}
grid <- expand.grid(k = modeloLasso$bestTune)
controle <- trainControl(method = "optimism_boot")
modeloLassoCV <- train(votos ~ ., 
               data = treinoK,
               method = "lasso",
               tuneGrid = grid,
               trControl = controle,
               preProcess = valoresPreProcessados)
modeloLassoCV
```

```{r}
predicaoLassoCV <- predict(modeloLassoCV)
dadosLassoCV <- data.frame(pred = predicaoLassoCV, obs = treino$votos)

lassoCV <- round(defaultSummary(dadosLassoCV), digits = 4)

lassoCV
```


#### 5 - Use esse último modelo treinado para prever os dados de teste disponíveis no challenge que criamos na plataforma Kaggle

```{r eval = FALSE}
modeloLassoCV$xlevels[["ocupacao"]] <- union(modeloLassoCV$xlevels[["ocupacao"]], levels(testeK$ocupacao))
predicao <- predict(modeloLassoCV, testeK)
ID <- testeK %>%
  select(sequencial_candidato)
colnames(ID)[colnames(ID)=="sequencial_candidato"] <- "ID"
arquivoCSV <- ID
arquivoCSV$votos <- predicao
arquivoCSV$votos[arquivoCSV$votos < 0] <- 0
write.csv(arquivoCSV, "sample_submission.csv", row.names=FALSE)
```



